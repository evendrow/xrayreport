{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from catr.configuration import Config\n",
    "from catr.models.utils import NestedTensor, nested_tensor_from_tensor_list, get_rank\n",
    "from catr.models.backbone import build_backbone\n",
    "from catr.models.transformer import build_transformer\n",
    "from catr.models.position_encoding import PositionEmbeddingSine\n",
    "from catr.models.caption import MLP\n",
    "\n",
    "import json\n",
    "\n",
    "from dataset.dataset import ImageFeatureDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_ethan import *\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), \"catr\"))\n",
    "from engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load(\"glove_embed.npy\")\n",
    "with open('word2ind.json') as json_file: \n",
    "    word2ind = json.load(json_file) \n",
    "with open('ind2word.json') as json_file: \n",
    "    ind2word = json.load(json_file) \n",
    "config = Config()\n",
    "config.device = 'cpu' # if running without GPU\n",
    "config.feature_dim = 1024\n",
    "config.pad_token_id = word2ind[\"<S>\"]\n",
    "config.hidden_dim = 300\n",
    "config.nheads = 10\n",
    "config.batch_size = 8\n",
    "config.vocab_size = words.shape[0]\n",
    "config.dir = '../mimic_features'\n",
    "config.__dict__[\"pre_embed\"] = torch.from_numpy(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n",
      "Number of params: 33908144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Xray_Captioner(\n",
       "  (input_proj): Conv2d(1024, 300, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (position_embedding): PositionEmbeddingSine()\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (embeddings): DecoderEmbeddings(\n",
       "      (word_embeddings): Embedding(23100, 300, padding_idx=1678)\n",
       "      (position_embeddings): Embedding(128, 300)\n",
       "      (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=300, out_features=512, bias=True)\n",
       "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (2): Linear(in_features=512, out_features=23100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, criterion = main(config)\n",
    "model = model.float()\n",
    "device = torch.device(config.device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dicts = [\n",
    "        {\"params\": [p for n, p in model.named_parameters(\n",
    "        ) if \"backbone\" not in n and p.requires_grad]},\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "            \"lr\": config.lr_backbone,\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "        param_dicts, lr=config.lr, weight_decay=config.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, config.lr_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 128\n",
      "Val: 32\n"
     ]
    }
   ],
   "source": [
    "dataset_train = ImageFeatureDataset(config, mode='train')\n",
    "dataset_val = ImageFeatureDataset(config, mode='val')\n",
    "\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "        sampler_train, config.batch_size, drop_last=True)\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        dataset_train, batch_sampler=batch_sampler_train, num_workers=config.num_workers)\n",
    "data_loader_val = DataLoader(dataset_val, config.batch_size,\n",
    "                                 sampler=sampler_val, drop_last=False, num_workers=config.num_workers)\n",
    "print(f\"Train: {len(dataset_train)}\")\n",
    "print(f\"Val: {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training..\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(config.checkpoint):\n",
    "    print(\"Loading Checkpoint...\")\n",
    "    checkpoint = torch.load(config.checkpoint, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    config.start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "print(\"Start Training..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:00<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 9.027783334255219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.61s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.783172607421875\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:01<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.678520172834396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.76054060459137\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.878822475671768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.130942761898041\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:13<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.056869998574257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.90s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.4725332856178284\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.524763137102127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2662988901138306\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:10<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.2473490238189697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.01s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.9581229090690613\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.985088735818863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.7227672338485718\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.8182372748851776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.86s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6525256037712097\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.768174171447754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.656706690788269\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.753058820962906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6459078192710876\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.7338963747024536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.86s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.629267603158951\n",
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.7085530534386635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6252678632736206\n",
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.667819380760193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.97s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.553814172744751\n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:08<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.593202792108059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.500924229621887\n",
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.539571166038513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4681789577007294\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:08<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.5090907737612724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.454487979412079\n",
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:08<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.4758152812719345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4394366443157196\n",
      "\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:08<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.436721995472908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.79s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4256466925144196\n",
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.3883387595415115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.404610514640808\n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:07<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.349529005587101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.91s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3863262832164764\n",
      "\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:07<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2985946238040924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  2.00s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.378326654434204\n",
      "\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:05<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.294106349349022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.80s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3755583465099335\n",
      "\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:07<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.283103197813034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.374040812253952\n",
      "\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:07<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2768838480114937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.79s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3758350908756256\n",
      "\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:07<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.27351263910532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3732486963272095\n",
      "\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:06<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.268472835421562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.78s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.373862475156784\n",
      "\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:08<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2637667655944824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.89s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3708381056785583\n",
      "\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:06<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2595183700323105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.79s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.373511165380478\n",
      "\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:07<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.256667785346508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.86s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3728419840335846\n",
      "\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:07<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2482321113348007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3705135583877563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist = []\n",
    "val_loss_hist = []\n",
    "\n",
    "for epoch in range(config.start_epoch, config.epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    epoch_loss = train_one_epoch(\n",
    "        model, criterion, data_loader_train, optimizer, device, epoch, config.clip_max_norm)\n",
    "    train_loss_hist.append(epoch_loss)\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Training Loss: {epoch_loss}\")\n",
    "\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }, config.checkpoint)\n",
    "\n",
    "    validation_loss = evaluate(model, criterion, data_loader_val, device)\n",
    "    val_loss_hist.append(validation_loss)\n",
    "    print(f\"Validation Loss: {validation_loss}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edward: note this makes a new caption as (<S>, 0, ..., 0) shouldn't we want as (<S>, <S>, ..., <S>)?\n",
    "def create_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, 0] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_report(captions):\n",
    "    all_reports = []\n",
    "    for report in captions:\n",
    "        if (report == word2ind[\"</s>\"]).any():\n",
    "            end_index = (report == word2ind[\"</s>\"]).nonzero()[0][0]\n",
    "            report = report[:end_index+1]\n",
    "        one_report = list(map(lambda x: ind2word[str(x)], report))\n",
    "        all_reports.append(one_report)\n",
    "    return all_reports\n",
    "\n",
    "def reports_to_sentence(reports):\n",
    "    return [' '.join(r) for r in make_report(reports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(images):\n",
    "    all_captions = []\n",
    "    model.eval()\n",
    "    for i in range(len(images)):\n",
    "        image = images[i:i+1]\n",
    "        caption, cap_mask = create_caption_and_mask(\n",
    "            config.pad_token_id, config.max_position_embeddings)\n",
    "        for i in range(config.max_position_embeddings - 1):\n",
    "            predictions = model(image, caption, cap_mask)\n",
    "            predictions = predictions[:, i, :]\n",
    "            predicted_id = torch.argmax(predictions, axis=-1)\n",
    "\n",
    "\n",
    "            caption[:, i+1] = predicted_id[0]\n",
    "            cap_mask[:, i+1] = False\n",
    "            \n",
    "            if predicted_id[0] == word2ind[\"</s>\"]:\n",
    "                break\n",
    "\n",
    "        all_captions.append(caption.numpy())\n",
    "#     return make_report(all_captions)\n",
    "    return all_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, image_mask, note, note_mask = next(iter(data_loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = evaluate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "report2 = evaluate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> The and lateral views of the chest . <s> The and is is is is . <s> The is the the . <s> The is is is is is is are . <s> The is is is is is is . <s> The is is the is is . <s> </s>',\n",
       " '<S> The and lateral views of the chest . <s> The . <s> The is is . <s> The is are is . <s> No is . <s> The is are is . <s> No \" \" \" \" \" . <s> </s>',\n",
       " '<S> The and lateral views of the chest . <s> The . <s> The is is . <s> The is are is is is are is . <s> The . <s> No . <s> No . <s> </s>',\n",
       " '<S> The and lateral views of the chest . <s> The . <s> The is is . <s> The is are is is is are is . <s> The is is are . <s> </s>',\n",
       " '<S> The and lateral the of the chest . <s> The . <s> The is is the . <s> The the the . <s> There is is the is is the the the . <s> There is is is is is . <s> The is is the is is the the . <s> There is is is is . <s> The . <s> </s>',\n",
       " '<S> The and lateral views of the chest . <s> The and the is is is . <s> The is the the . <s> The is is the is is the the the . <s> There is is the is is the . <s> The is the is is the the the . <s> The is is is . <s> The . <s> </s>',\n",
       " '<S> The and lateral views of the chest . <s> The . <s> The is is . <s> The is is is . <s> No is . <s> The is is is . <s> </s>',\n",
       " '<S> The and lateral views of the chest . <s> The . <s> The is is is . <s> The is is is is are is . <s> The is is are . <s> The is is is are is . <s> The is . <s> The is is . <s> </s>']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_np = np.asarray(report).squeeze(1)\n",
    "reports_to_sentence(report_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([63]),)\n",
      "(array([35]),)\n",
      "(array([45]),)\n",
      "(array([47]),)\n",
      "(array([61]),)\n",
      "(array([89]),)\n",
      "(array([29]),)\n",
      "(array([53]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> AS COMPARED TO THE PRIOR EXAMINATION DATED ___ , THERE HAS BEEN NO SIGNIFICANT INTERVAL CHANGE . <S> THERE IS NO EVIDENCE OF FOCAL CONSOLIDATION , PLEURAL EFFUSION , PNEUMOTHORAX , OR FRANK PULMONARY EDEMA . <S> THE CARDIOMEDIASTINAL SILHOUETTE IS WITHIN NORMAL LIMITS . <S> THERE IS PERSISTENT THORACIC KYPHOSIS WITH MILD WEDGING OF A MID THORACIC VERTEBRAL BODY . <S> </S>',\n",
       " '<S> PA AND LATERAL CHEST RADIOGRAPHS AGAIN DEMONSTRATE SEVERE HYPERINFLATION AND DIFFUSE BRONCHIECTASIS . <S> THERE IS NO FOCAL CONSOLIDATION , PLEURAL EFFUSION , OR PNEUMOTHORAX . <S> THE CARDIOMEDIASTINAL SILHOUETTE IS STABLE . <S> </S>',\n",
       " '<S> RETICULAR OPACITIES AT THE LUNG BASES BILATERALLY LIKELY REPRESENT MILD ATELECTASIS . <S> THERE IS MILD <UNK> <UNK> SCARRING . <S> NO EVIDENCE OF PNEUMONIA , PLEURAL EFFUSION , OR PNEUMOTHORAX . <S> HEART SIZE AND MEDIASTINAL CONTOURS ARE WITHIN NORMAL LIMITS . <S> </S>',\n",
       " '<S> THE LUNGS ARE CLEAR OF FOCAL CONSOLIDATION , PLEURAL EFFUSION OR PNEUMOTHORAX . <S> THE HEART SIZE IS NORMAL . <S> THE MEDIASTINAL CONTOURS ARE NORMAL . <S> MULTIPLE SURGICAL CLIPS PROJECT OVER THE LEFT BREAST , AND OLD LEFT RIB FRACTURES ARE NOTED . <S> </S>',\n",
       " '<S> DISTAL TIP OF THE <UNK> IS NOW IN THE FUNDUS OF THE STOMACH . <S> THIS COULD BE ADVANCED AN ADDITIONAL 5 CM FOR MORE OPTIMAL PLACEMENT . <S> THERE ARE UNCHANGED BILATERAL PLEURAL EFFUSIONS , LEFT GREATER THAN RIGHT . <S> A PLEURAL CATHETER IS SEEN AT THE RIGHT BASE . <S> THERE ARE NO PNEUMOTHORACES IDENTIFIED . <S> </S>',\n",
       " '<S> CHAIN SUTURE PROJECTS OVER THE RIGHT UPPER HEMITHORAX . <S> THERE IS PERSISTENT LINEAR ATELECTASIS IN THE LEFT MID LUNG AND WORSENING ATELECTASIS AT THE LEFT BASE . <S> OPACITY PROJECTING JUST ANTERIOR TO THE SPINE AT THE LUNG BASE ON THE LATERAL RADIOGRAPH IS NOT APPRECIABLY CHANGED SINCE ___ . <S> THERE IS NO AIRSPACE OPACITY WORRISOME FOR PNEUMONIA . <S> THE CARDIOMEDIASTINAL SILHOUETTE AND HILAR CONTOURS ARE STABLE . <S> THE HEART IS NOT ENLARGED . <S> THERE IS NO PLEURAL EFFUSION OR PNEUMOTHORAX . <S> </S>',\n",
       " '<S> MILD BASILAR ATELECTASIS IS SEEN WITHOUT FOCAL CONSOLIDATION . <S> NO PLEURAL EFFUSION OR PNEUMOTHORAX IS SEEN . <S> THE CARDIAC AND MEDIASTINAL SILHOUETTES ARE STABLE . <S> </S>',\n",
       " '<S> FRONTAL AND LATERAL VIEWS OF THE CHEST . <S> THERE IS PERSISTENT BLUNTING OF LEFT COSTOPHRENIC ANGLE LATERALLY SUGGESTIVE OF UNDERLYING SCARRING OR PLEURAL THICKENING . <S> THE LUNGS ARE OTHERWISE CLEAR . <S> <UNK> SILHOUETTE IS WITHIN NORMAL LIMITS . <S> MEDIAN STERNOTOMY WIRES AND MEDIASTINAL CLIPS AGAIN NOTED . <S> </S>']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_to_sentence(np.asarray(note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 129])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> THE AND LATERAL VIEWS OF THE CHEST . <S> THE AND IS IS IS IS . <S> THE IS THE THE . <S> THE IS IS IS IS IS IS ARE . <S> THE IS IS IS IS IS IS . <S> THE IS IS THE IS IS . <S> </S> \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(image[0].unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1024, 8, 8])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
