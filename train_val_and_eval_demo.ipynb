{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from catr.configuration import Config\n",
    "from catr.models.utils import NestedTensor, nested_tensor_from_tensor_list, get_rank\n",
    "from catr.models.backbone import build_backbone\n",
    "from catr.models.transformer import build_transformer\n",
    "from catr.models.position_encoding import PositionEmbeddingSine\n",
    "from catr.models.caption import MLP\n",
    "\n",
    "import json\n",
    "\n",
    "from dataset.dataset import ImageFeatureDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_ethan import *\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), \"catr\"))\n",
    "from engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load(\"glove_embed.npy\")\n",
    "with open('word2ind.json') as json_file: \n",
    "    word2ind = json.load(json_file) \n",
    "with open('ind2word.json') as json_file: \n",
    "    ind2word = json.load(json_file) \n",
    "config = Config()\n",
    "config.device = 'cpu' # if running without GPU\n",
    "config.feature_dim = 1024\n",
    "config.pad_token_id = word2ind[\"<S>\"]\n",
    "config.hidden_dim = 300\n",
    "config.nheads = 10\n",
    "config.batch_size = 8\n",
    "config.vocab_size = words.shape[0]\n",
    "config.dir = '../mimic_features'\n",
    "config.__dict__[\"pre_embed\"] = torch.from_numpy(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n",
      "Number of params: 33908144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Xray_Captioner(\n",
       "  (input_proj): Conv2d(1024, 300, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (position_embedding): PositionEmbeddingSine()\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (embeddings): DecoderEmbeddings(\n",
       "      (word_embeddings): Embedding(23100, 300, padding_idx=1678)\n",
       "      (position_embeddings): Embedding(128, 300)\n",
       "      (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=300, out_features=512, bias=True)\n",
       "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (2): Linear(in_features=512, out_features=23100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, criterion = main(config)\n",
    "model = model.float()\n",
    "device = torch.device(config.device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dicts = [\n",
    "        {\"params\": [p for n, p in model.named_parameters(\n",
    "        ) if \"backbone\" not in n and p.requires_grad]},\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "            \"lr\": config.lr_backbone,\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "        param_dicts, lr=config.lr, weight_decay=config.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, config.lr_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 128\n",
      "Val: 32\n"
     ]
    }
   ],
   "source": [
    "dataset_train = ImageFeatureDataset(config, mode='train')\n",
    "dataset_val = ImageFeatureDataset(config, mode='val')\n",
    "\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "        sampler_train, config.batch_size, drop_last=True)\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        dataset_train, batch_sampler=batch_sampler_train, num_workers=config.num_workers)\n",
    "data_loader_val = DataLoader(dataset_val, config.batch_size,\n",
    "                                 sampler=sampler_val, drop_last=False, num_workers=config.num_workers)\n",
    "print(f\"Train: {len(dataset_train)}\")\n",
    "print(f\"Val: {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(config.checkpoint):\n",
    "#     print(\"Loading Checkpoint...\")\n",
    "#     checkpoint = torch.load(config.checkpoint, map_location='cpu')\n",
    "#     model.load_state_dict(checkpoint['model'])\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#     lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "#     config.start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "# print(\"Start Training..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:05<00:00,  4.09s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 8.994897067546844\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.32s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.5243847370147705\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:16<00:00,  4.78s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.349693596363068\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:19<00:00,  4.95s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.247378408908844\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:15<00:00,  4.71s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.331391327083111\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:14<00:00,  4.64s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6650395914912224\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:15<00:00,  4.71s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0157253444194794\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:14<00:00,  4.64s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.35607119370251894\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:17<00:00,  4.84s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.050020587688777596\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:14<00:00,  4.65s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.005038461880758405\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:13<00:00,  4.60s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0016293625376420096\n",
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:13<00:00,  4.61s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0010347500137868337\n",
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:15<00:00,  4.72s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0008029518394323532\n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:15<00:00,  4.71s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0006613179248233791\n",
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:14<00:00,  4.66s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0005619054245471489\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:14<00:00,  4.63s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0004829111549042864\n",
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:13<00:00,  4.60s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00041845033956633415\n",
      "\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:15<00:00,  4.71s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0003684014554892201\n",
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:09<00:00,  4.34s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0003267332249379251\n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:05<00:00,  4.08s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002901677398767788\n",
      "\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:06<00:00,  4.16s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002723209054238396\n",
      "\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:08<00:00,  4.26s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002697525324037997\n",
      "\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:08<00:00,  4.26s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00026673813226807397\n",
      "\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:16<00:00,  4.81s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002639629619807238\n",
      "\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:21<00:00,  5.11s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002609207294881344\n",
      "\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:26<00:00,  5.43s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00025754482521733735\n",
      "\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:21<00:00,  5.08s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002550127974245697\n",
      "\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:17<00:00,  4.83s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002527617889427347\n",
      "\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:14<00:00,  4.67s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00024961370036180597\n",
      "\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:16<00:00,  4.80s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00024606246734037995\n",
      "\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:15<00:00,  4.74s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00024320608281414025\n",
      "\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:17<00:00,  4.85s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00024107854824251262\n",
      "\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:19<00:00,  4.97s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002377206537858001\n",
      "\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:22<00:00,  5.13s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00023530996895715361\n",
      "\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:17<00:00,  4.83s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002324893421246088\n",
      "\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:21<00:00,  5.07s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00022955309486860642\n",
      "\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:17<00:00,  4.86s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00022674565207125852\n",
      "\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:18<00:00,  4.88s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.000223631438529992\n",
      "\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:19<00:00,  4.94s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00022090036236477317\n",
      "\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:20<00:00,  5.06s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002185371358791599\n",
      "\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:22<00:00,  5.16s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021652666237059748\n",
      "\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:23<00:00,  5.21s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021633422966260696\n",
      "\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:21<00:00,  5.08s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021571641991613433\n",
      "\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:18<00:00,  4.94s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021541965816140873\n",
      "\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:22<00:00,  5.14s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021500049660971854\n",
      "\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:31<00:00,  9.45s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021493165422725724\n",
      "\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:12<00:00,  8.29s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021499830108950846\n",
      "\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:36<00:00,  6.02s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021452845248859376\n",
      "\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:01<00:00,  7.57s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021425773320515873\n",
      "\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [02:11<00:00,  8.19s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021373142226366326\n",
      "\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:54<00:00,  7.13s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002141254690286587\n",
      "\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:41<00:00,  6.32s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021361487961257808\n",
      "\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:30<00:00,  5.66s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021291400116751902\n",
      "\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:23<00:00,  5.20s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021276463030517334\n",
      "\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:21<00:00,  5.07s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021240569731162395\n",
      "\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:18<00:00,  4.93s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021234001724224072\n",
      "\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:21<00:00,  5.09s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021149735039216466\n",
      "\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:26<00:00,  5.39s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021135795395821333\n",
      "\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:59<00:00,  7.47s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021091596227051923\n",
      "\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:20<00:00,  5.05s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021081947215861874\n",
      "\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:19<00:00,  4.98s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002107128993884544\n",
      "\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:18<00:00,  4.92s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021059488335595233\n",
      "\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:24<00:00,  5.30s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.00021039398961875122\n",
      "\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:53<00:00,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0002106818146785372\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist = []\n",
    "val_loss_hist = []\n",
    "\n",
    "for epoch in range(config.start_epoch, config.epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    epoch_loss = train_one_epoch(\n",
    "        model, criterion, data_loader_train, optimizer, device, epoch, config.clip_max_norm)\n",
    "    train_loss_hist.append(epoch_loss)\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Training Loss: {epoch_loss}\")\n",
    "\n",
    "#     torch.save({\n",
    "#         'model': model.state_dict(),\n",
    "#         'optimizer': optimizer.state_dict(),\n",
    "#         'lr_scheduler': lr_scheduler.state_dict(),\n",
    "#         'epoch': epoch,\n",
    "#     }, config.checkpoint)\n",
    "\n",
    "#     validation_loss = evaluate(model, criterion, data_loader_val, device)\n",
    "#     val_loss_hist.append(validation_loss)\n",
    "#     print(f\"Validation Loss: {validation_loss}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbf020c1ee0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# plt.grid()\n",
    "plt.plot(train_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edward: note this makes a new caption as (<S>, 0, ..., 0) shouldn't we want as (<S>, <S>, ..., <S>)?\n",
    "def create_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, 0] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_report(captions):\n",
    "    all_reports = []\n",
    "    for report in captions:\n",
    "        if (report == word2ind[\"</s>\"]).any():\n",
    "            end_index = (report == word2ind[\"</s>\"]).nonzero()[0][0]\n",
    "            report = report[:end_index+1]\n",
    "        one_report = list(map(lambda x: ind2word[str(x)], report))\n",
    "        all_reports.append(one_report)\n",
    "    return all_reports\n",
    "\n",
    "def reports_to_sentence(reports):\n",
    "    return [' '.join(r) for r in make_report(reports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(images):\n",
    "    all_captions = []\n",
    "    model.eval()\n",
    "    for i in range(len(images)):\n",
    "        image = images[i:i+1]\n",
    "        caption, cap_mask = create_caption_and_mask(\n",
    "            config.pad_token_id, config.max_position_embeddings)\n",
    "        for i in range(config.max_position_embeddings - 1):\n",
    "            predictions = model(image, caption, cap_mask)\n",
    "            predictions = predictions[:, i, :]\n",
    "            predicted_id = torch.argmax(predictions, axis=-1)\n",
    "\n",
    "\n",
    "            caption[:, i+1] = predicted_id[0]\n",
    "            cap_mask[:, i+1] = False\n",
    "            \n",
    "            if predicted_id[0] == word2ind[\"</s>\"]:\n",
    "                break\n",
    "\n",
    "        all_captions.append(caption.numpy())\n",
    "#     return make_report(all_captions)\n",
    "    return all_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, image_mask, note, note_mask = next(iter(data_loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = evaluate(image[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_np = np.asarray(report).squeeze(1)\n",
    "reports_to_sentence(report_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>',\n",
       " '<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>',\n",
       " '<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>',\n",
       " '<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>',\n",
       " '<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>',\n",
       " '<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>',\n",
       " '<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>',\n",
       " '<S> There is no focal consolidation , pleural effusion or pneumothorax . <s> Bilateral nodular opacities that most likely represent nipple shadows . <s> The cardiomediastinal silhouette is normal . <s> Clips project over the left lung , potentially within the breast . <s> The imaged upper abdomen is unremarkable . <s> Chronic deformity of the posterior left sixth and seventh ribs are noted . <s> </s>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_to_sentence(np.asarray(note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 129])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> THE AND LATERAL VIEWS OF THE CHEST . <S> THE AND IS IS IS IS . <S> THE IS THE THE . <S> THE IS IS IS IS IS IS ARE . <S> THE IS IS IS IS IS IS . <S> THE IS IS THE IS IS . <S> </S> \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(image[0].unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1024, 8, 8])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
