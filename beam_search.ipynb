{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from queue import PriorityQueue\n",
    "\n",
    "from dataset.dataset import ImageFeatureDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_ethan import *\n",
    "from catr.configuration import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load(\"glove_embed.npy\")\n",
    "with open('word2ind.json') as json_file: \n",
    "    word2ind = json.load(json_file) \n",
    "with open('ind2word.json') as json_file: \n",
    "    ind2word = json.load(json_file) \n",
    "\n",
    "config = Config()\n",
    "config.device = 'cpu'\n",
    "config.feature_dim = 1024\n",
    "config.pad_token_id = word2ind[\"<S>\"]\n",
    "config.hidden_dim = 300\n",
    "config.nheads = 10\n",
    "config.batch_size = 64\n",
    "config.encoder_type = 1\n",
    "config.vocab_size = words.shape[0]\n",
    "config.dir = '../mimic_features_double'\n",
    "config.__dict__[\"pre_embed\"] = torch.from_numpy(words).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n",
      "Number of params: 33370520\n"
     ]
    }
   ],
   "source": [
    "model, criterion = main(config) \n",
    "model = model.float()\n",
    "device = torch.device(config.device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = ImageFeatureDataset(config, mode='val')\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "data_loader_val = DataLoader(dataset_val, 1,\n",
    "                             sampler=sampler_val, drop_last=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint...\n"
     ]
    }
   ],
   "source": [
    "# Load from checkpoint\n",
    "CHECKPOINT_NAME = \"../../models/checkpoint_imagenet_10_tf.pth\"\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_NAME, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "print(\"Loading Checkpoint...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def get_bleu_score(truths, predicteds, weights_to_be_used=[0.25, 0.25, 0.25, 0.25]):\n",
    "    scores = []\n",
    "    for index in range(len(truths)):\n",
    "        truth = truths[index]\n",
    "        predicted = predicteds[index]\n",
    "        try:\n",
    "            score = nltk.translate.bleu_score.sentence_bleu([truth], predicted, weights=weights_to_be_used)\n",
    "        except:\n",
    "            score = 0\n",
    "        scores.append(score)\n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edward: note this makes a new caption as (<S>, 0, ..., 0) shouldn't we want as (<S>, <S>, ..., <S>)?\n",
    "def create_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, 0] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template\n",
    "\n",
    "def make_report(captions):\n",
    "    all_reports = []\n",
    "    for report in captions:\n",
    "        if (report == word2ind[\"</s>\"]).any():\n",
    "            end_index = (report == word2ind[\"</s>\"]).nonzero()[0][0]\n",
    "            report = report[:end_index+1]\n",
    "        one_report = list(map(lambda x: ind2word[str(x)], report))\n",
    "        all_reports.append(one_report)\n",
    "    return all_reports\n",
    "\n",
    "def reports_to_sentence(reports):\n",
    "    return [' '.join(r) for r in make_report(reports)]\n",
    "\n",
    "def evaluate(images):\n",
    "    all_captions = []\n",
    "    model.eval()\n",
    "    for i in range(len(images)):\n",
    "        image = images[i:i+1]\n",
    "        caption, cap_mask = create_caption_and_mask(\n",
    "            config.pad_token_id, config.max_position_embeddings)\n",
    "#         caption.to(\"cuda\")\n",
    "        for i in range(config.max_position_embeddings - 1):\n",
    "            with torch.no_grad():\n",
    "                predictions = model(image, caption, cap_mask).to(config.device)\n",
    "            predictions = predictions[:, i, :]\n",
    "            predicted_id = torch.argmax(predictions, axis=-1)\n",
    "\n",
    "\n",
    "            caption[:, i+1] = predicted_id[0]\n",
    "            cap_mask[:, i+1] = False\n",
    "            \n",
    "            if predicted_id[0] == word2ind[\"</s>\"]:\n",
    "                break\n",
    "\n",
    "        all_captions.append(caption.numpy())\n",
    "#     return make_report(all_captions)\n",
    "    return all_captions\n",
    "\n",
    "def bleu(truth_in, generated_in):\n",
    "    truth = truth_in.replace(\"<S>\", \"\").replace(\"<s>\", \"\").replace(\"</s>\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\"  \", \" \").split(\" \")\n",
    "    generated = generated_in.replace(\"<S>\", \"\").replace(\"<s>\", \"\").replace(\"</s>\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\"  \", \" \").split(\" \")\n",
    "    truth = [y for y in truth if y != ''] \n",
    "    generated = [y for y in generated if y != ''] \n",
    "    bs4 = nltk.translate.bleu_score.sentence_bleu([truth], generated, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "    bs3 = nltk.translate.bleu_score.sentence_bleu([truth], generated, weights=[1./3., 1./3., 1./3.])\n",
    "    bs2 = nltk.translate.bleu_score.sentence_bleu([truth], generated, weights=[0.5, 0.5])\n",
    "    bs1 = nltk.translate.bleu_score.sentence_bleu([truth], generated, weights=[1.])\n",
    "    return bs1, bs2, bs3, bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        return self.logp / float(self.leng - 1 + 1e-6)\n",
    "    \n",
    "# def beam_decode(model, config, target_tensor, decoder_hiddens, encoder_outputs=None):\n",
    "def beam_decode(model, image, beam_width=5, topk=1):\n",
    "    '''\n",
    "    :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n",
    "    :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
    "    :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
    "    :return: decoded_batch\n",
    "    '''\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "#     beam_width = 5\n",
    "#     topk = 5  # how many sentence do you want to generate\n",
    "    decoded_batch = []\n",
    "    \n",
    "    SOS_token = word2ind[\"<S>\"]\n",
    "    EOS_token = word2ind[\"</s>\"]\n",
    "    \n",
    "    caption, cap_mask = create_caption_and_mask(\n",
    "#             config.pad_token_id, config.max_position_embeddings)\n",
    "            SOS_token, config.max_position_embeddings)\n",
    "    caption[:,1:] = EOS_token\n",
    "    \n",
    "    # Number of sentence to generate\n",
    "    endnodes = []\n",
    "    number_required = min((topk + 1), topk - len(endnodes))\n",
    "#     print(number_required, \"required.\")\n",
    "    \n",
    "    # starting node -  hidden vector, previous node, word id, logp, length\n",
    "    node = BeamSearchNode(cap_mask, None, caption, 0, 1)\n",
    "    nodes = PriorityQueue()\n",
    "\n",
    "    # start the queue\n",
    "    nodes.put((-node.eval(), node))\n",
    "    qsize = 1\n",
    "    \n",
    "    # start beam search\n",
    "    while True:\n",
    "        # give up when decoding takes too long\n",
    "        if qsize > 5000: \n",
    "\n",
    "            print(\"taking too long\")\n",
    "            break\n",
    "\n",
    "        # fetch the best node\n",
    "        score, n = nodes.get()\n",
    "        decoder_input = n.wordid\n",
    "        decoder_mask = n.h\n",
    "#         decoder_hidden = n.h\n",
    "\n",
    "        if n.leng == config.max_position_embeddings or n.wordid[0,n.leng-1].item() == EOS_token:\n",
    "            endnodes.append((score, n))\n",
    "            # if we reached maximum # of sentences required\n",
    "            if len(endnodes) >= number_required:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "#         if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "#             endnodes.append((score, n))\n",
    "#             # if we reached maximum # of sentences required\n",
    "#             if len(endnodes) >= number_required:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "        # decode for one step using decoder\n",
    "#         decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(image, decoder_input, decoder_mask).to(config.device)\n",
    "        predictions = predictions[0, n.leng-1, :] # shape: [22058]\n",
    "#         predicted_id = torch.argmax(predictions, axis=-1)\n",
    "\n",
    "        # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "        log_prob, indexes = torch.topk(predictions, beam_width)\n",
    "        nextnodes = []\n",
    "\n",
    "        for new_k in range(beam_width):\n",
    "            predicted_id = indexes[new_k]\n",
    "            log_p = log_prob[new_k].item()\n",
    "            \n",
    "            new_caption = decoder_input.detach().clone()\n",
    "            new_mask = decoder_mask.detach().clone()\n",
    "            \n",
    "            new_caption[:, n.leng] = predicted_id\n",
    "            new_mask[:, n.leng] = False\n",
    "\n",
    "            node = BeamSearchNode(new_mask, n, new_caption, n.logp + log_p, n.leng + 1)\n",
    "            score = -node.eval()\n",
    "            nextnodes.append((score, node))\n",
    "\n",
    "        # put them into queue\n",
    "        for i in range(len(nextnodes)):\n",
    "            score, nn = nextnodes[i]\n",
    "            nodes.put((score, nn))\n",
    "            # increase qsize\n",
    "        qsize += len(nextnodes) - 1\n",
    "\n",
    "    # choose nbest paths, back trace them\n",
    "    if len(endnodes) < topk:\n",
    "        for _ in range(topk-len(endnodes)):\n",
    "            endnodes.append(nodes.get())\n",
    "\n",
    "    print(\"Got \", len(endnodes), \" end nodes\")\n",
    "    utterances = []\n",
    "    for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "#         utterance = []\n",
    "#         utterance.append(n.wordid)\n",
    "#         # back trace\n",
    "#         while n.prevNode != None:\n",
    "#             n = n.prevNode\n",
    "#             utterance.append(n.wordid)\n",
    "\n",
    "#         utterance = utterance[::-1]\n",
    "        utterances.append(n.wordid)\n",
    "\n",
    "    return utterances\n",
    "        \n",
    "        \n",
    "    # decoding goes sentence by sentence\n",
    "    for idx in range(target_tensor.size(0)):\n",
    "        if isinstance(decoder_hiddens, tuple):  # LSTM case\n",
    "            decoder_hidden = (decoder_hiddens[0][:,idx, :].unsqueeze(0),decoder_hiddens[1][:,idx, :].unsqueeze(0))\n",
    "        else:\n",
    "            decoder_hidden = decoder_hiddens[:, idx, :].unsqueeze(0)\n",
    "#         encoder_output = encoder_outputs[:,idx, :].unsqueeze(1)\n",
    "\n",
    "        # Start with the start of the sentence token\n",
    "        decoder_input = torch.LongTensor([[SOS_token]], device=device)\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = min((topk + 1), topk - len(endnodes))\n",
    "\n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "\n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000:\n",
    "                print(\"taking too long\")\n",
    "                break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    print(\"Got all required\")\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_width)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_width):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "\n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(topk)]\n",
    "\n",
    "        utterances = []\n",
    "        for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "            utterance = []\n",
    "            utterance.append(n.wordid)\n",
    "            # back trace\n",
    "            while n.prevNode != None:\n",
    "                n = n.prevNode\n",
    "                utterance.append(n.wordid)\n",
    "\n",
    "            utterance = utterance[::-1]\n",
    "            utterances.append(utterance)\n",
    "\n",
    "        decoded_batch.append(utterances)\n",
    "\n",
    "    return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETHAN_NOTE = \"<S> The heart size is normal . <s> The hilar and mediastinal contours are normal . <s> No focal consolidations concerning for pneumonia are identified . <s> There is no pleural effusion or pneumothorax . <s> The visualized osseous structures are unremarkable . <s> </s>\"\n",
    "\n",
    "def do_beam_iter(image, note, note_mask):\n",
    "    \n",
    "    beam_1 = []\n",
    "    beam_5 = []\n",
    "    beam_10 = []\n",
    "    \n",
    "    report = evaluate(image)\n",
    "    report_np = np.asarray(report).squeeze(1)\n",
    "    \n",
    "    truth = reports_to_sentence(np.asarray(note[:,:]))[0]\n",
    "    print('[GT]', truth)\n",
    "    print()\n",
    "    generated = reports_to_sentence(report_np)[0]\n",
    "    print('[Beam 1 Pred]', generated)\n",
    "    bs1, bs2, bs3, bs4 = bleu(truth, generated)\n",
    "    print(\"[Beam 1] Bleu score: {0:.4f} {1:.4f} {2:.4f} {3:.4f}\".format(bs1, bs2, bs3, bs4))\n",
    "    \n",
    "    beam_1 = [bs1, bs2, bs3, bs4]\n",
    "    \n",
    "    print()\n",
    "    decoded_sentences = beam_decode(model, image, beam_width=5, topk=1)\n",
    "    gen = reports_to_sentence(decoded_sentences[0].numpy())[0]\n",
    "    print(\"[Beam 5 Pred] \",gen)\n",
    "    bs1, bs2, bs3, bs4 = bleu(truth, gen)\n",
    "    beam_5 = [bs1, bs2, bs3, bs4]\n",
    "    print(\"[Beam 5] Bleu score: {0:.4f} {1:.4f} {2:.4f} {3:.4f}\".format(bs1, bs2, bs3, bs4))\n",
    "        \n",
    "    print()\n",
    "    decoded_sentences = beam_decode(model, image, beam_width=10, topk=1)\n",
    "    gen = reports_to_sentence(decoded_sentences[0].numpy())[0]\n",
    "    print(\"[Beam 10 Pred] \",gen)\n",
    "    bs1, bs2, bs3, bs4 = bleu(truth, gen)\n",
    "    beam_10 = [bs1, bs2, bs3, bs4]\n",
    "    print(\"[Beam 10] Bleu score: {0:.4f} {1:.4f} {2:.4f} {3:.4f}\".format(bs1, bs2, bs3, bs4))\n",
    "    print()\n",
    "    \n",
    "    bs1, bs2, bs3, bs4 = bleu(truth, ETHAN_NOTE)\n",
    "    beam_ethan = [bs1, bs2, bs3, bs4]\n",
    "    print(\"[Beam ethan] Bleu score: {0:.4f} {1:.4f} {2:.4f} {3:.4f}\".format(bs1, bs2, bs3, bs4))\n",
    "    \n",
    "        \n",
    "    print('---------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    return beam_1, beam_5, beam_10, beam_ethan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S> No evidence of consolidation to suggest pneumonia is seen . <s> There is some retrocardiac atelectasis . <s> A small left pleural effusion may be present . <s> No pneumothorax is seen . <s> No pulmonary edema . <s> A right granuloma is unchanged . <s> The heart is mildly enlarged , unchanged . <s> There is tortuosity of the aorta . <s> </s>'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_beam_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GT] <S> No evidence of consolidation to suggest pneumonia is seen . <s> There is some retrocardiac atelectasis . <s> A small left pleural effusion may be present . <s> No pneumothorax is seen . <s> No pulmonary edema . <s> A right granuloma is unchanged . <s> The heart is mildly enlarged , unchanged . <s> There is tortuosity of the aorta . <s> </s>\n",
      "\n",
      "[Beam 1 Pred] <S> AP upright and lateral views of the chest provided . <s> Lung volumes are low . <s> There is mild left basal atelectasis . <s> No convincing evidence for pneumonia or edema . <s> No large effusion or pneumothorax . <s> The cardiomediastinal silhouette is stable . <s> Imaged osseous structures are intact . <s> No free air below the right hemidiaphragm is seen . <s> </s>\n",
      "[Beam 1] Bleu score: 0.3800 0.1525 0.0000 0.0000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-3b4b7083998f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbeam_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_ethan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_beam_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mbeam_1_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbeam_5_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-230-c507e5919e9c>\u001b[0m in \u001b[0;36mdo_beam_iter\u001b[0;34m(image, note, note_mask)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdecoded_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreports_to_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Beam 5 Pred] \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-229-d603e6ca5bfb>\u001b[0m in \u001b[0;36mbeam_decode\u001b[0;34m(model, image, beam_width, topk)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleng\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# shape: [22058]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m#         predicted_id = torch.argmax(predictions, axis=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/CS 236G/project/xrayreportgeneration/transformer_ethan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img_features, target, target_mask)\u001b[0m\n\u001b[1;32m     59\u001b[0m         hs = self.transformer(img_embeds, mask,\n\u001b[1;32m     60\u001b[0m                               pos, target, target_mask)\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/CS 236G/project/xrayreportgeneration/catr/models/caption.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "beam_1_list = []\n",
    "beam_5_list = []\n",
    "beam_10_list = []\n",
    "beam_ethan_list = []\n",
    "\n",
    "iters = 0\n",
    "for image, note, note_mask in data_loader_val:\n",
    "    \n",
    "    \n",
    "    beam_1, beam_5, beam_10, beam_ethan = do_beam_iter(image, note, note_mask)\n",
    "    beam_1_list.append(beam_1)\n",
    "    beam_5_list.append(beam_5)\n",
    "    beam_10_list.append(beam_10)\n",
    "    beam_ethan_list.append(beam_ethan)\n",
    "\n",
    "    iters += 1\n",
    "    if iters >= 128:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beam 1 Bleu score: 0.3220 0.2219 0.1090 0.0000\n",
    "Beam 5 Bleu score: 0.0909 0.0615 0.0317 0.0000\n",
    "\n",
    "Beam 1 Bleu score: 0.1315 0.0771 0.0517 0.0000\n",
    "Beam 5 Bleu score: 0.0323 0.0162 0.0000 0.0000\n",
    "\n",
    "Beam 1 Bleu score: 0.2559 0.1497 0.0876 0.0000\n",
    "Beam 5 Bleu score: 0.0812 0.0501 0.0273 0.0000\n",
    "\n",
    "Beam 1 Bleu score: 0.1667 0.0595 0.0000 0.0000\n",
    "Beam 5 Bleu score: 0.1600 0.0808 0.0514 0.0000\n",
    "\n",
    "Beam 1 Bleu score: 0.2652 0.1967 0.1603 0.1376\n",
    "Beam 5 Bleu score: 0.1225 0.1083 0.0992 0.0908\n",
    "\n",
    "Beam 1 Bleu score: 0.0869 0.0553 0.0363 0.0000\n",
    "Beam 5 Bleu score: 0.1048 0.0595 0.0291 0.0000\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, note, note_mask = next(iter(data_loader_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = evaluate(image)\n",
    "report_np = np.asarray(report).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S> No evidence of consolidation to suggest pneumonia is seen . <s> There is some retrocardiac atelectasis . <s> A small left pleural effusion may be present . <s> No pneumothorax is seen . <s> No pulmonary edema . <s> A right granuloma is unchanged . <s> The heart is mildly enlarged , unchanged . <s> There is tortuosity of the aorta . <s> </s>'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = reports_to_sentence(np.asarray(note[:,:]))[0]\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S> AP upright and lateral views of the chest provided . <s> Lung volumes are low . <s> There is mild left basal atelectasis . <s> No convincing evidence for pneumonia or edema . <s> No large effusion or pneumothorax . <s> The cardiomediastinal silhouette is stable . <s> Imaged osseous structures are intact . <s> No free air below the right hemidiaphragm is seen . <s> </s>'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = reports_to_sentence(report_np)[0]\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score: 0.3800 0.1525 0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "bs1, bs2, bs3, bs4 = bleu(truth, generated)\n",
    "print(\"Bleu score: {0:.4f} {1:.4f} {2:.4f} {3:.4f}\".format(bs1, bs2, bs3, bs4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 required.\n",
      "Got  5  end nodes\n"
     ]
    }
   ],
   "source": [
    "decoded_sentences = beam_decode(model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter  0 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> </s>\n",
      "[BLEU] Bleu score: 0.3391 0.2105 0.0998 0.0000\n",
      "[iter  1 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> No displaced fracture is identified . <s> </s>\n",
      "[BLEU] Bleu score: 0.3680 0.2213 0.1036 0.0000\n",
      "[iter  2 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> No displaced fracture is seen . <s> </s>\n",
      "[BLEU] Bleu score: 0.3680 0.2213 0.1036 0.0000\n",
      "[iter  3 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> No displaced rib fracture is seen . <s> </s>\n",
      "[BLEU] Bleu score: 0.3687 0.2216 0.1038 0.0000\n",
      "[iter  4 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> </s>\n",
      "[BLEU] Bleu score: 0.2187 0.1341 0.0726 0.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(decoded_sentences)):\n",
    "    gen = reports_to_sentence(decoded_sentences[i].numpy())[0]\n",
    "    print(\"[iter \",i,\"] \",gen)\n",
    "    bs1, bs2, bs3, bs4 = bleu(truth, gen)\n",
    "    print(\"[BLEU] Bleu score: {0:.4f} {1:.4f} {2:.4f} {3:.4f}\".format(bs1, bs2, bs3, bs4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter  0 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> </s>\n",
      "[BLEU] Bleu score: 0.3391 0.2105 0.0998 0.0000\n",
      "[iter  1 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> No displaced fracture is identified . <s> </s>\n",
      "[BLEU] Bleu score: 0.3680 0.2213 0.1036 0.0000\n",
      "[iter  2 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> No displaced fracture is seen . <s> </s>\n",
      "[BLEU] Bleu score: 0.3680 0.2213 0.1036 0.0000\n",
      "[iter  3 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> No overt pulmonary edema is seen . <s> No displaced rib fracture is seen . <s> </s>\n",
      "[BLEU] Bleu score: 0.3687 0.2216 0.1038 0.0000\n",
      "[iter  4 ]  <S> AP upright and lateral views of the chest were obtained . <s> Lung volumes are low . <s> No focal consolidation is seen . <s> No pleural effusion or pneumothorax . <s> The cardiac and mediastinal silhouettes are stable . <s> </s>\n",
      "[BLEU] Bleu score: 0.2187 0.1341 0.0726 0.0000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S> No evidence of consolidation to suggest pneumonia is seen . <s> There is some retrocardiac atelectasis . <s> A small left pleural effusion may be present . <s> No pneumothorax is seen . <s> No pulmonary edema . <s> A right granuloma is unchanged . <s> The heart is mildly enlarged , unchanged . <s> There is tortuosity of the aorta . <s> </s>'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
