{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from catr.configuration import Config\n",
    "from catr.models.utils import NestedTensor, nested_tensor_from_tensor_list, get_rank\n",
    "from catr.models.backbone import build_backbone\n",
    "from catr.models.transformer import build_transformer\n",
    "from catr.models.position_encoding import PositionEmbeddingSine\n",
    "from catr.models.caption import MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, define our custom caption class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xray_Captioner(nn.Module):\n",
    "    def __init__(self, transformer, feature_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv2d(\n",
    "            feature_dim, hidden_dim, kernel_size=1) # project feature dimension\n",
    "        self.position_embedding = PositionEmbeddingSine(hidden_dim//2, normalize=True)\n",
    "        self.transformer = transformer\n",
    "        self.mlp = MLP(hidden_dim, 512, vocab_size, 3)\n",
    "\n",
    "    def forward(self, img_features, target, target_mask):\n",
    "        # The input mask here is all zeros, meaning we look at the whole image\n",
    "        # The mask here is more of a formality, oringinally implemented to \n",
    "        # let the model accept different image sizes. Not needed here.\n",
    "        b, c, h, w = img_features.shape\n",
    "        mask = torch.zeros((b, h, w), dtype=torch.bool, device=img_features.device)\n",
    "\n",
    "        # Get projected image features and positional embedding\n",
    "        img_embeds = self.input_proj(img_features)\n",
    "        pos = self.position_embedding(NestedTensor(img_embeds, mask))\n",
    "        \n",
    "        # Run through transformer -> linear -> softmax\n",
    "        hs = self.transformer(img_embeds, mask,\n",
    "                              pos, target, target_mask)\n",
    "        out = self.mlp(hs.permute(1, 0, 2))\n",
    "        return out\n",
    "    \n",
    "\n",
    "def build_model(config):\n",
    "    transformer = build_transformer(config)\n",
    "    model = Xray_Captioner(transformer, config.feature_dim, config.hidden_dim, config.vocab_size)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method builds the model like we will during training/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This method uses a config file to appropriately create the model.\n",
    "This includes setting the device and specifying a random seed    \n",
    "''' \n",
    "def main(config):\n",
    "    # initialize device we're runnign this on\n",
    "    device = torch.device(config.device)\n",
    "    print(f'Initializing Device: {device}')\n",
    "\n",
    "    # specify the random seed for deterministic behavior\n",
    "    seed = config.seed + get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # create the model\n",
    "    model, criterion = build_model(config)\n",
    "    model.to(device)\n",
    "    \n",
    "    # sanity check\n",
    "    n_parameters = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Number of params: {n_parameters}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n",
      "Number of params: 41525306\n"
     ]
    }
   ],
   "source": [
    "# Create a sample config file\n",
    "# feature_dim is not specified by default, so we need to set it\n",
    "config = Config()\n",
    "config.device = 'cpu' # if running without GPU\n",
    "config.feature_dim = 1024\n",
    "\n",
    "# Create the model!\n",
    "xray_model = main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run some random stuff through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create initial caption and mask\n",
    "def create_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, :] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from get_matrix_from_cnn import *\n",
    "# from get_notes_and_image_paths import *\n",
    "from get_word_embeddings import *\n",
    "# from image_feature_dataset import *\n",
    "from load_glove_840B_300d import *\n",
    "# from make_study_dictionary import *\n",
    "from dataset.dataset import ImageFeatureDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dict = main_get_notes_and_image_paths(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dict[\"p10/p10274145/s53356050/4e60f3da-37ed157d-a469a568-0b2ee907-4b01c924.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFeatureDataset('../mimic_features/paths.csv',\n",
    "                             '../mimic_features/')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 8, 8])\n",
      "[('<S>',), ('No',), ('evidence',), ('of',), ('consolidation',), ('to',), ('suggest',), ('pneumonia',), ('is',), ('seen',), ('.',), ('<s>',), ('There',), ('is',), ('some',), ('retrocardiac',), ('atelectasis',), ('.',), ('<s>',), ('A',), ('small',), ('left',), ('pleural',), ('effusion',), ('may',), ('be',), ('present',), ('.',), ('<s>',), ('No',), ('pneumothorax',), ('is',), ('seen',), ('.',), ('<s>',), ('No',), ('pulmonary',), ('edema',), ('.',), ('<s>',), ('A',), ('right',), ('granuloma',), ('is',), ('unchanged',), ('.',), ('<s>',), ('The',), ('heart',), ('is',), ('mildly',), ('enlarged',), (',',), ('unchanged',), ('.',), ('<s>',), ('There',), ('is',), ('tortuosity',), ('of',), ('the',), ('aorta',), ('.',), ('<s>',), ('</s>',)]\n"
     ]
    }
   ],
   "source": [
    "features, note = next(iter(dataloader))\n",
    "print(features.shape)\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.load('../mimic_features/eb2fabb7-4bbc8aab-d7371282-08e5bcb5-de2e430a.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 23094  words loaded!\n"
     ]
    }
   ],
   "source": [
    "words = main_get_word_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make word embedding dictionary\n",
    "weights = np.zeros((len(set(words.keys())), 300))\n",
    "word2ind = {}\n",
    "ind2word = {}\n",
    "current_ind = 0\n",
    "for word in sorted(words.keys()):\n",
    "    word2ind[word] = current_ind\n",
    "    ind2word[current_ind] = word\n",
    "    weights[current_ind] = words[word]\n",
    "    current_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create starter caption and caption mask\n",
    "start_token = word2ind[\"<S>\"]\n",
    "caption, cap_mask = create_caption_and_mask(\n",
    "    start_token, config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = extract_image_features(\"/Users/ethanschonfeld/Desktop/mimic_cxr\", \n",
    "#                                 [\"p10/p10274145/s53356050/4e60f3da-37ed157d-a469a568-0b2ee907-4b01c924.jpg\"], \n",
    "#                                 \"densenet121\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_torch = torch.from_numpy(features.transpose((0, 3, 1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 128 is out of bounds for dimension 1 with size 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dc2a0f0991a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# get highest predicted word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcurrent_caption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_number\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcurrent_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_number\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0miteration_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 128 is out of bounds for dimension 1 with size 128"
     ]
    }
   ],
   "source": [
    "# getting predicted sentence for an image\n",
    "current_caption, current_mask = create_caption_and_mask(start_token, config.max_position_embeddings)\n",
    "iteration_number = 1\n",
    "last_word = word2ind[\"<S>\"]\n",
    "while iteration_number <= config.max_position_embeddings and last_word != word2ind[\"</s>\"]:\n",
    "    predictions = xray_model(features, current_caption, current_mask)\n",
    "    # get highest predicted word\n",
    "    word = torch.argmax(predictions[:,0,:], axis=-1)\n",
    "    current_caption[:, iteration_number] = word\n",
    "    current_mask[:, iteration_number] = False\n",
    "    iteration_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<S>\n",
      "uniformly\n",
      "Outward\n",
      "Flexure\n",
      "Flexure\n",
      "these\n",
      "Outward\n",
      "uniformly\n",
      "these\n",
      "emanating\n",
      "Flexure\n",
      "Flexure\n",
      "Month\n",
      "Flexure\n",
      "Flexure\n",
      "these\n",
      "Flexure\n",
      "13:38\n",
      "emanating\n",
      "Yestarday\n",
      "these\n",
      "Flexure\n",
      "these\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Yestarday\n",
      "Flexure\n",
      "13:38\n",
      "Flexure\n",
      "emanating\n",
      "affects\n",
      "emanating\n",
      "these\n",
      "Flexure\n",
      "Flexure\n",
      "these\n",
      "Flexure\n",
      "Flexure\n",
      "emanating\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Make\n",
      "emanating\n",
      "these\n",
      "emanating\n",
      "Flexure\n",
      "these\n",
      "these\n",
      "emanating\n",
      "these\n",
      "these\n",
      "Flexure\n",
      "uniformly\n",
      "these\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "these\n",
      "Flexure\n",
      "these\n",
      "Flexure\n",
      "these\n",
      "these\n",
      "Flexure\n",
      "Flexure\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "28393",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f633bcc6a0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_caption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_caption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 28393"
     ]
    }
   ],
   "source": [
    "for index in range(current_caption.shape[1]):\n",
    "    print(ind2word[current_caption[0, index].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
