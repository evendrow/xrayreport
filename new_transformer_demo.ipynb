{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from catr.configuration import Config\n",
    "from catr.models.utils import NestedTensor, nested_tensor_from_tensor_list, get_rank\n",
    "from catr.models.backbone import build_backbone\n",
    "from catr.models.transformer import build_transformer\n",
    "from catr.models.position_encoding import PositionEmbeddingSine\n",
    "from catr.models.caption import MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, define our custom caption class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xray_Captioner(nn.Module):\n",
    "    def __init__(self, transformer, feature_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv2d(\n",
    "            feature_dim, hidden_dim, kernel_size=1) # project feature dimension\n",
    "        self.position_embedding = PositionEmbeddingSine(hidden_dim//2, normalize=True)\n",
    "        self.transformer = transformer\n",
    "        self.mlp = MLP(hidden_dim, 512, vocab_size, 3)\n",
    "\n",
    "    def forward(self, img_features, target, target_mask):\n",
    "        # The input mask here is all zeros, meaning we look at the whole image\n",
    "        # The mask here is more of a formality, oringinally implemented to \n",
    "        # let the model accept different image sizes. Not needed here.\n",
    "        b, c, h, w = img_features.shape\n",
    "        mask = torch.zeros((b, h, w), dtype=torch.bool, device=img_features.device)\n",
    "\n",
    "        # Get projected image features and positional embedding\n",
    "        img_embeds = self.input_proj(img_features)\n",
    "        pos = self.position_embedding(NestedTensor(img_embeds, mask))\n",
    "        \n",
    "        # Run through transformer -> linear -> softmax\n",
    "        hs = self.transformer(img_embeds, mask,\n",
    "                              pos, target, target_mask)\n",
    "        out = self.mlp(hs.permute(1, 0, 2))\n",
    "        return out\n",
    "    \n",
    "\n",
    "def build_model(config):\n",
    "    transformer = build_transformer(config)\n",
    "    model = Xray_Captioner(transformer, config.feature_dim, config.hidden_dim, config.vocab_size)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method builds the model like we will during training/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This method uses a config file to appropriately create the model.\n",
    "This includes setting the device and specifying a random seed    \n",
    "''' \n",
    "def main(config):\n",
    "    # initialize device we're runnign this on\n",
    "    device = torch.device(config.device)\n",
    "    print(f'Initializing Device: {device}')\n",
    "\n",
    "    # specify the random seed for deterministic behavior\n",
    "    seed = config.seed + get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # create the model\n",
    "    model, criterion = build_model(config)\n",
    "    model.to(device)\n",
    "    \n",
    "    # sanity check\n",
    "    n_parameters = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Number of params: {n_parameters}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n",
      "Number of params: 41525306\n"
     ]
    }
   ],
   "source": [
    "# Create a sample config file\n",
    "# feature_dim is not specified by default, so we need to set it\n",
    "config = Config()\n",
    "config.device = 'cpu' # if running without GPU\n",
    "config.feature_dim = 1024\n",
    "\n",
    "# Create the model!\n",
    "xray_model = main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run some random stuff through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create initial caption and mask\n",
    "def create_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, 0] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template\n",
    "\n",
    "\n",
    "# Create starter caption and caption mask\n",
    "start_token = 102 # why not lol\n",
    "caption, cap_mask = create_caption_and_mask(\n",
    "    start_token, config.max_position_embeddings)\n",
    "\n",
    "# Initialize features to randomness\n",
    "fake_features = torch.randn(1, 1024, 8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30522\n",
      "My word: 22644\n"
     ]
    }
   ],
   "source": [
    "# Get some predictions\n",
    "predictions = xray_model(fake_features, caption, cap_mask)\n",
    "\n",
    "# Get the first word\n",
    "word_preds = predictions[:,0,:]\n",
    "word = torch.argmax(word_preds, axis=-1)\n",
    "print(\"Vocab size:\", config.vocab_size)\n",
    "print(\"My word:\", word.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
