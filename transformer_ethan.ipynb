{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from catr.configuration import Config\n",
    "from catr.models.utils import NestedTensor, nested_tensor_from_tensor_list, get_rank\n",
    "from catr.models.backbone import build_backbone\n",
    "from catr.models.transformer import build_transformer\n",
    "from catr.models.position_encoding import PositionEmbeddingSine\n",
    "from catr.models.caption import MLP\n",
    "\n",
    "from get_matrix_from_cnn import *\n",
    "from get_notes_and_image_paths import *\n",
    "from get_word_embeddings import *\n",
    "from image_feature_dataset import *\n",
    "from load_glove_840B_300d import *\n",
    "from make_study_dictionary import *\n",
    "\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, define our custom caption class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xray_Captioner(nn.Module):\n",
    "    def __init__(self, transformer, feature_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv2d(\n",
    "            feature_dim, hidden_dim, kernel_size=1) # project feature dimension\n",
    "        self.position_embedding = PositionEmbeddingSine(hidden_dim//2, normalize=True)\n",
    "        self.transformer = transformer\n",
    "        self.mlp = MLP(hidden_dim, 512, vocab_size, 3)\n",
    "\n",
    "    def forward(self, img_features, target, target_mask):\n",
    "        # The input mask here is all zeros, meaning we look at the whole image\n",
    "        # The mask here is more of a formality, oringinally implemented to \n",
    "        # let the model accept different image sizes. Not needed here.\n",
    "        b, c, h, w = img_features.shape\n",
    "        mask = torch.zeros((b, h, w), dtype=torch.bool, device=img_features.device)\n",
    "\n",
    "        # Get projected image features and positional embedding\n",
    "        img_embeds = self.input_proj(img_features)\n",
    "        pos = self.position_embedding(NestedTensor(img_embeds, mask))\n",
    "        \n",
    "        # Run through transformer -> linear -> softmax\n",
    "        hs = self.transformer(img_embeds, mask,\n",
    "                              pos, target, target_mask)\n",
    "        out = self.mlp(hs.permute(1, 0, 2))\n",
    "        return out\n",
    "    \n",
    "\n",
    "def build_model(config):\n",
    "    transformer = build_transformer(config)\n",
    "    model = Xray_Captioner(transformer, config.feature_dim, config.hidden_dim, config.vocab_size)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method builds the model like we will during training/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This method uses a config file to appropriately create the model.\n",
    "This includes setting the device and specifying a random seed    \n",
    "''' \n",
    "def main(config):\n",
    "    # initialize device we're runnign this on\n",
    "    device = torch.device(config.device)\n",
    "    print(f'Initializing Device: {device}')\n",
    "\n",
    "    # specify the random seed for deterministic behavior\n",
    "    seed = config.seed + get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # create the model\n",
    "    model, criterion = build_model(config)\n",
    "    model.to(device)\n",
    "    \n",
    "    # sanity check\n",
    "    n_parameters = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Number of params: {n_parameters}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = main_get_notes_and_image_paths(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict[\"p10/p10274145/s53356050/4e60f3da-37ed157d-a469a568-0b2ee907-4b01c924.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = main_get_word_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make word embedding dictionary\n",
    "weights = np.zeros((len(set(words.keys())), 300))\n",
    "word2ind = {}\n",
    "ind2word = {}\n",
    "current_ind = 0\n",
    "for word in sorted(words.keys()):\n",
    "    word2ind[word] = current_ind\n",
    "    ind2word[current_ind] = word\n",
    "    weights[current_ind] = words[word]\n",
    "    current_ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "embed_dim must be divisible by num_heads",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b1ab8ea3246b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create the model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mxray_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-e071863d1bda>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# create the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8bc2e3d0fcb2>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXray_Captioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/xray/xrayreportgeneration/catr/models/transformer.py\u001b[0m in \u001b[0;36mbuild_transformer\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     return Transformer(\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/xray/xrayreportgeneration/catr/models/transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, activation, normalize_before, return_intermediate_dec)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                                 dropout, activation, normalize_before)\n\u001b[1;32m     20\u001b[0m         \u001b[0mencoder_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalize_before\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/xray/xrayreportgeneration/catr/models/transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, nhead, dim_feedforward, dropout, activation, normalize_before)\u001b[0m\n\u001b[1;32m    128\u001b[0m                  activation=\"relu\", normalize_before=False):\n\u001b[1;32m    129\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiheadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Implementation of Feedforward model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_feedforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embed_dim must be divisible by num_heads\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qkv_same_embed_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: embed_dim must be divisible by num_heads"
     ]
    }
   ],
   "source": [
    "# Create a sample config file\n",
    "# feature_dim is not specified by default, so we need to set it\n",
    "config = Config()\n",
    "config.device = 'cpu' # if running without GPU\n",
    "config.feature_dim = 1024\n",
    "config.pad_token_id = word2ind[\"<S>\"]\n",
    "config.hidden_dim = 300\n",
    "config.nheads = 10\n",
    "\n",
    "# Create the model!\n",
    "xray_model = main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create initial caption and mask\n",
    "def create_evaluation_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, :] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create starter caption and caption mask\n",
    "start_token = word2ind[\"<S>\"]\n",
    "caption, cap_mask = create_evaluation_caption_and_mask(\n",
    "    start_token, config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = extract_image_features(\"../mimic_cxr\", \n",
    "                                [\"p10/p10274145/s53356050/4e60f3da-37ed157d-a469a568-0b2ee907-4b01c924.jpg\"]\n",
    "                                ,\"densenet121\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = matrix.transpose((0, 3, 1, 2))\n",
    "features = torch.from_numpy(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "uniformly\n",
      "Flexure\n",
      "Yestarday\n",
      "Yestarday\n",
      "Flexure\n",
      "uniformly\n",
      "Lap-Band\n",
      "Flexure\n",
      "tin\n",
      "Difficult\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "uniformly\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "hospital\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "uniformly\n",
      "Flexure\n",
      "uniformly\n",
      "IMPLANTABLE\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "Flexure\n",
      "uniformly\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "hospital\n",
      "uniformly\n",
      "Flexure\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "tin\n",
      "uniformly\n",
      "uniformly\n",
      "Left-side\n",
      "uniformly\n",
      "Resembles\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "DECISION\n",
      "Flexure\n",
      "hospital\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "Flexure\n",
      "Flexure\n",
      "Difficult\n",
      "uniformly\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "ANalysis\n",
      "Flexure\n",
      "issued\n",
      "Doubted\n",
      "Flexure\n",
      "16:42\n",
      "uniformly\n",
      "uniformly\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "Resembles\n",
      "Flexure\n",
      "uniformly\n",
      "uniformly\n",
      "cardiac\n",
      "uniformly\n",
      "uniformly\n",
      "Lap-Band\n"
     ]
    }
   ],
   "source": [
    "# getting predicted sentence for an image\n",
    "current_caption, current_mask = create_evaluation_caption_and_mask(start_token, config.max_position_embeddings)\n",
    "iteration_number = 1\n",
    "last_word = word2ind[\"<S>\"]\n",
    "while iteration_number < config.max_position_embeddings and last_word != word2ind[\"</s>\"]:\n",
    "    predictions = xray_model(features, current_caption, current_mask)\n",
    "    # get highest predicted word\n",
    "    word = torch.argmax(predictions[:,0,:], axis=-1)\n",
    "    try:\n",
    "        print(ind2word[word.item()])\n",
    "    except:\n",
    "        pass\n",
    "    current_caption[:, iteration_number] = word\n",
    "    current_mask[:, iteration_number] = False\n",
    "    iteration_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_backbone': 1e-05,\n",
       " 'lr': 0.0001,\n",
       " 'epochs': 30,\n",
       " 'lr_drop': 20,\n",
       " 'start_epoch': 0,\n",
       " 'weight_decay': 0.0001,\n",
       " 'backbone': 'resnet101',\n",
       " 'position_embedding': 'sine',\n",
       " 'dilation': True,\n",
       " 'device': 'cpu',\n",
       " 'seed': 42,\n",
       " 'batch_size': 32,\n",
       " 'num_workers': 8,\n",
       " 'checkpoint': './checkpoint.pth',\n",
       " 'clip_max_norm': 0.1,\n",
       " 'hidden_dim': 300,\n",
       " 'pad_token_id': 1678,\n",
       " 'max_position_embeddings': 128,\n",
       " 'layer_norm_eps': 1e-12,\n",
       " 'dropout': 0.1,\n",
       " 'vocab_size': 30522,\n",
       " 'enc_layers': 6,\n",
       " 'dec_layers': 6,\n",
       " 'dim_feedforward': 2048,\n",
       " 'nheads': 8,\n",
       " 'pre_norm': True,\n",
       " 'dir': '../coco',\n",
       " 'limit': -1,\n",
       " 'feature_dim': 1024}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
