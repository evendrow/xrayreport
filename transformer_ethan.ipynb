{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from catr.configuration import Config\n",
    "from catr.models.utils import NestedTensor, nested_tensor_from_tensor_list, get_rank\n",
    "from catr.models.backbone import build_backbone\n",
    "from catr.models.transformer import build_transformer\n",
    "from catr.models.position_encoding import PositionEmbeddingSine\n",
    "from catr.models.caption import MLP\n",
    "\n",
    "from get_word_embeddings import *\n",
    "from load_glove_840B_300d import *\n",
    "\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, define our custom caption class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xray_Captioner(nn.Module):\n",
    "    def __init__(self, transformer, feature_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv2d(\n",
    "            feature_dim, hidden_dim, kernel_size=1) # project feature dimension\n",
    "        self.position_embedding = PositionEmbeddingSine(hidden_dim//2, normalize=True)\n",
    "        self.transformer = transformer\n",
    "        self.mlp = MLP(hidden_dim, 512, vocab_size, 3)\n",
    "\n",
    "    def forward(self, img_features, target, target_mask):\n",
    "        # The input mask here is all zeros, meaning we look at the whole image\n",
    "        # The mask here is more of a formality, oringinally implemented to \n",
    "        # let the model accept different image sizes. Not needed here.\n",
    "        b, c, h, w = img_features.shape\n",
    "        mask = torch.zeros((b, h, w), dtype=torch.bool, device=img_features.device)\n",
    "\n",
    "        # Get projected image features and positional embedding\n",
    "        img_embeds = self.input_proj(img_features)\n",
    "        pos = self.position_embedding(NestedTensor(img_embeds, mask))\n",
    "        \n",
    "        # Run through transformer -> linear -> softmax\n",
    "        hs = self.transformer(img_embeds, mask,\n",
    "                              pos, target, target_mask)\n",
    "        out = self.mlp(hs.permute(1, 0, 2))\n",
    "        return out\n",
    "    \n",
    "\n",
    "def build_model(config):\n",
    "    transformer = build_transformer(config)\n",
    "    model = Xray_Captioner(transformer, config.feature_dim, config.hidden_dim, config.vocab_size)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method builds the model like we will during training/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This method uses a config file to appropriately create the model.\n",
    "This includes setting the device and specifying a random seed    \n",
    "''' \n",
    "def main(config):\n",
    "    # initialize device we're runnign this on\n",
    "    device = torch.device(config.device)\n",
    "    print(f'Initializing Device: {device}')\n",
    "\n",
    "    # specify the random seed for deterministic behavior\n",
    "    seed = config.seed + get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # create the model\n",
    "    model, criterion = build_model(config)\n",
    "    model.to(device)\n",
    "    \n",
    "    # sanity check\n",
    "    n_parameters = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Number of params: {n_parameters}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load(\"glove_embed.npy\")\n",
    "with open('word2ind.json') as json_file: \n",
    "    word2ind = json.load(json_file) \n",
    "with open('ind2word.json') as json_file: \n",
    "    ind2word = json.load(json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n",
      "Number of params: 33908144\n"
     ]
    }
   ],
   "source": [
    "# Create a sample config file\n",
    "# feature_dim is not specified by default, so we need to set it\n",
    "config = Config()\n",
    "config.device = 'cpu' # if running without GPU\n",
    "config.feature_dim = 1024\n",
    "config.pad_token_id = word2ind[\"<S>\"]\n",
    "config.hidden_dim = 300\n",
    "config.nheads = 10\n",
    "config.vocab_size = words.shape[0]\n",
    "config.__dict__[\"pre_embed\"] = torch.from_numpy(words)\n",
    "\n",
    "# Create the model!\n",
    "xray_model = main(config)\n",
    "xray_model = xray_model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create initial caption and mask\n",
    "def create_evaluation_caption_and_mask(start_token, max_length):\n",
    "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
    "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
    "\n",
    "    caption_template[:, :] = start_token\n",
    "    mask_template[:, 0] = False\n",
    "\n",
    "    return caption_template, mask_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.cnn_utils import extract_image_features\n",
    "from dataset.dataset import ImageFeatureDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFeatureDataset('../mimic_features/paths.csv',\n",
    "                             '../mimic_features/')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "iterations = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:29\n",
      "7:28\n",
      "Parrot\n",
      "FAILURE\n",
      "THOUGH\n",
      "7:28\n",
      "interpretability\n",
      "MANIFESTING\n",
      "Frank\n",
      "05:29\n",
      "FAILURE\n",
      "interpretability\n",
      "interpretability\n",
      "cranial\n",
      "interpretability\n",
      "05:29\n",
      "05:29\n",
      "Fibrous\n",
      "Mastectomy\n",
      "Parrot\n",
      "5:03\n",
      "05:29\n",
      "05:29\n",
      "5:03\n",
      "5:03\n",
      "Parrot\n",
      "5:03\n",
      "Frank\n",
      "MANIFESTING\n",
      "Altered\n",
      "7:28\n",
      "Worry\n",
      "05:29\n",
      "Aiming\n",
      "7:28\n",
      "5:03\n",
      "Worry\n",
      "Intermittent\n",
      "7:28\n",
      "7:28\n",
      "Intermittent\n",
      "LINEAR\n",
      "5:03\n",
      "05:29\n",
      "Worry\n",
      "05:29\n",
      "interpretability\n",
      "FAILURE\n",
      "ENTERIC\n",
      "FAILURE\n",
      "FAILURE\n",
      "05:29\n",
      "05:29\n",
      "interpretability\n",
      "5:03\n",
      "05:29\n",
      "Frank\n",
      "interpretability\n",
      "Parrot\n",
      "MANIFESTING\n",
      "interpretability\n",
      "interpretability\n",
      "7:28\n",
      "Pin\n",
      "Worry\n",
      "7:28\n",
      "Mastectomy\n",
      "05:29\n",
      "05:29\n",
      "Worry\n",
      "ARTERIES\n",
      "5:03\n",
      "Frank\n",
      "Intermittent\n",
      "14:11\n",
      "7:28\n",
      "7:28\n",
      "MANIFESTING\n",
      "7:28\n",
      "interpretability\n",
      "05:29\n",
      "Parrot\n",
      "5:03\n",
      "FAILURE\n",
      "interpretability\n",
      "Worry\n",
      "Mastectomy\n",
      "7:28\n",
      "05:29\n",
      "plans\n",
      "05:29\n",
      "7:28\n",
      "CAME\n",
      "Distinction\n",
      "FAILURE\n",
      "05:29\n",
      "Mastectomy\n",
      "well-aligned\n",
      "detectably\n",
      "Frank\n",
      "THOUGH\n",
      "05:29\n",
      "FAILURE\n",
      "05:29\n",
      "Distinction\n",
      "5:03\n",
      "5:03\n",
      "Mastectomy\n",
      "5:03\n",
      "Frank\n",
      "interpretability\n",
      "Frank\n",
      "FAILURE\n",
      "MILD\n",
      "normalization\n",
      "05:29\n",
      "Parrot\n",
      "05:29\n",
      "05:29\n",
      "Parrot\n",
      "Aiming\n",
      "05:29\n",
      "Worry\n",
      "Frank\n",
      "interpretability\n",
      "p.o\n",
      "7:28\n"
     ]
    }
   ],
   "source": [
    "# getting predicted sentence for an image\n",
    "image, note = next(iterations)\n",
    "start_token = word2ind[\"<S>\"]\n",
    "current_caption, current_mask = create_evaluation_caption_and_mask(start_token, config.max_position_embeddings)\n",
    "iteration_number = 1\n",
    "last_word = start_token\n",
    "while iteration_number < config.max_position_embeddings and last_word != word2ind[\"</s>\"]:\n",
    "    predictions = xray_model(image.double(), current_caption, current_mask)\n",
    "    # get highest predicted word\n",
    "    word = torch.argmax(predictions[:,0,:], axis=-1)\n",
    "    try:\n",
    "        print(ind2word[str(word.item())])\n",
    "    except:\n",
    "        pass\n",
    "    current_caption[:, iteration_number] = word\n",
    "    current_mask[:, iteration_number] = False\n",
    "    iteration_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
